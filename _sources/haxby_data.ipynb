{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d052dd",
   "metadata": {},
   "source": [
    "(haxby-dataset)=\n",
    "# The Haxby dataset\n",
    "\n",
    "## Downloading the data\n",
    " In the field of functional magnetic resonance imaging (fMRI), one of the first studies which have demonstrated the feasibility of brain decoding was the study by Haxby and colleagues (2001) {cite:p}`Haxby2001-vt`. Subjects were presented with various images drawn from different categories. In this tutorial, we will try to decode the category of the image presented to the subject from brain data. We are first going to use nilearn to download one subject (number 4) from the Haxby dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13541796",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import datasets\n",
    "# We are fetching the data for subject 4\n",
    "data_dir = os.path.join('..', 'data')\n",
    "sub_no = 4\n",
    "haxby_dataset = datasets.fetch_haxby(subjects=[sub_no], fetch_stimuli=True, data_dir=data_dir)\n",
    "func_file = haxby_dataset.func[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca38dd",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "The data includes `nii` files, which contains images of brain volumes, either anatomical or functional. We can examine one functional volume using nilearn's plotting tools. Because fmri data are 4D we use [nilearn.image.mean_img](https://nilearn.github.io/modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img) to extract the average brain volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ddb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "plotting.view_img(mean_img(func_file), threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf4cb3",
   "metadata": {},
   "source": [
    "Note that it is very hard to see the anatomy of the brain with that type of image. But it is not designed to capture brain anatomy, but rather changes of brain activity over time, through the coupling of neuronal activity with the oxygenation of blood vessels.\n",
    "\n",
    "```{admonition} Interactive viewer\n",
    ":class: tip\n",
    "The viewer `plotting.view_img` is interactive. You can click on the brain volume to explore different slices. You can learn about the three anatomical planes: sagittal (`x`), coronal (`y`) and axial (`z`) in the [wikipedia article](https://en.wikipedia.org/wiki/Anatomical_plane).\n",
    "```\n",
    "\n",
    "## Preparing the fMRI data\n",
    "```{figure} haxby_data/masker.png\n",
    "---\n",
    "width: 800px\n",
    "name: masker-fig\n",
    "---\n",
    "A `Masker` object is used to convert a 4D volume (space + time) into a data array, where each column is a voxel or brain region (features) and each row is a time point (samples). Figure from the [nilearn documentation](https://nilearn.github.io/stable/manipulating_images/masker_objects.html).\n",
    "```\n",
    "Instead of keeping the fMRI data as a 4D array (3D spatial coordinates + time), we are going to extract the time series associated with a mask of the ventral temporal cortex. This mask has been generated as part of the Haxby et al. (2001) study, and highlights a part of the brain specialized in the processing of visual information, and which contains areas sensitive to different types of image categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filename = haxby_dataset.mask_vt[0]\n",
    "# Let's visualize it, using the subject's anatomical image as a\n",
    "# background\n",
    "plotting.plot_roi(mask_filename, bg_img=haxby_dataset.anat[0],\n",
    "                  cmap='Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26cf36",
   "metadata": {},
   "source": [
    "We use one of the nilearn maskers to extract the fMRI time series associated just with this mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_filename, standardize=True, detrend=True)\n",
    "# Selecting data\n",
    "X = masker.fit_transform(func_file)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81703afe",
   "metadata": {},
   "source": [
    "We can see that the dataset has 1452 time samples (number of rows) and 675 voxels in the mask (number of columns).\n",
    "\n",
    "```{admonition} Nilearn maskers\n",
    ":class: tip\n",
    "Nilearn maskers are very versatile and offer many approaches to extract a time series array from 4D data, as well as reshape back an array into a series of brain volumes. You can learn more about nilearn maskers in this [documentation](https://nilearn.github.io/stable/manipulating_images/masker_objects.html).\n",
    "```\n",
    "\n",
    "## Preparing the cognitive annotations\n",
    "\n",
    "Now, we are going to extract cognitive annotations, that is values which tell us what type of images the subject was viewing at each time point. Let's look at the first 20 annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], delimiter=' ')\n",
    "display(behavioral.iloc[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0f5a4",
   "metadata": {},
   "source": [
    "So let's extract the labels for each time points. We can check that the number of annotations match exactly the number of samples we had in `X`. We can also check all the annotation categories available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = behavioral['labels']\n",
    "categories = y.unique()\n",
    "print(categories)\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd104463",
   "metadata": {},
   "source": [
    "These annotations correspond to the category of the image subjects were watching at each time point. Samples of images for each category are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1365c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting import show\n",
    "\n",
    "stimulus_information = haxby_dataset.stimuli\n",
    "\n",
    "for stim_type in stimulus_information:\n",
    "  # skip control images, there are too many\n",
    "  if stim_type != 'controls':\n",
    "\n",
    "     file_names = stimulus_information[stim_type]\n",
    "     file_names = file_names[0:16]\n",
    "     fig, axes = plt.subplots(4, 4)\n",
    "     fig.suptitle(stim_type)\n",
    "\n",
    "     for img_path, ax in zip(file_names, axes.ravel()):\n",
    "         ax.imshow(plt.imread(img_path), cmap=plt.cm.gray)\n",
    "\n",
    "     for ax in axes.ravel():\n",
    "         ax.axis(\"off\")\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fb3e3",
   "metadata": {},
   "source": [
    "Note that for each image category, a number of scrambled images were also presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309be8ce",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "for stim_num in range(len(stimulus_information['controls'])):\n",
    "    stim_type = stimulus_information['controls'][stim_num][0]\n",
    "    file_names = stimulus_information['controls'][stim_num][1]  \n",
    "    file_names = file_names[0:16]\n",
    "    fig, axes = plt.subplots(4, 4)\n",
    "    fig.suptitle(stim_type)\n",
    "\n",
    "    for img_path, ax in zip(file_names, axes.ravel()):\n",
    "     ax.imshow(plt.imread(img_path), cmap=plt.cm.gray)\n",
    "\n",
    "    for ax in axes.ravel():\n",
    "     ax.axis(\"off\")\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6093a2",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   22,
   31,
   34,
   38,
   56,
   62,
   65,
   71,
   82,
   86,
   88,
   94,
   96,
   122,
   124,
   141
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}